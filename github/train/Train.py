# åŠ è½½ä¸€äº›è¾…åŠ©å‡½æ•°
import pickle
import os
import shutil
import copy

# åŠ è½½ numpy å’Œ plt
import numpy as np
import matplotlib.pyplot as plt
from math import ceil

# åŠ è½½ pytorch
import torch
import torch.nn as nn

# åŠ è½½æ¨¡å‹
from VAE import TransformerVAE

# åŠ è½½ pytorch ä¼˜åŒ–å™¨
import torch.optim as optim

# åŠ è½½ pytorch çš„æ•°æ®é›†å’Œæ•°æ®é›†åŠ è½½å™¨
from torch.utils.data import Dataset, DataLoader

# åŠ è½½åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å‡½æ•°åº“
from torch.utils.data import random_split

# å­¦ä¹ ç‡é¢„çƒ­ä¸è°ƒåº¦å™¨
from torch.optim.lr_scheduler import OneCycleLR

# æ£€æŸ¥ CUDA æ˜¯å¦å¯ç”¨
if torch.cuda.is_available():
    device = torch.device("cuda:0")
    print("Using GPU1:", torch.cuda.get_device_name(0))
else:
    device = torch.device("cpu")
    print("CUDA is not available. Using CPU instead.")

#################################################################################
## å®šä¹‰è¶…å‚æ•°ï¼Œè¯»å–æ–‡ä»¶

# æ˜¯å¦è¯»å–å·²ç»ä¿å­˜çš„æƒé‡
Read_Weight = False

# å®šä¹‰ dropout_rate
DR = 0.1

# å­¦ä¹ ç‡
LR = 0.0001

# å®šä¹‰è®­ç»ƒçš„æ€» epoch æ•°ï¼š
num_epochs = 500

# è®­ç»ƒé›†å æ¯”
Train_Rate = 0.85

# å®šä¹‰æ‰¹å¤§å°
BS = 8

#è¯»å–ä¿å­˜ RNA åµŒå…¥ tensor çš„å­—å…¸
# embs_path = '/home/meixy23/TVAE/NEW/output_emb4.pkl'
# with open(embs_path, 'rb') as file:
#     RNA_emb_dict = pickle.load(file)

# # è¯»å–ä¿å­˜æ ‡ç­¾ tensor çš„å­—å…¸
# labels_path = '/home/meixy23/TVAE/NEW/output_pairs4.pkl'
# with open(labels_path, 'rb') as file:
#     RNA_pair_labels_dict = pickle.load(file)

embs_path = '/home/meixy23/TVAE/Rf1_RNA_emb_dict.pkl'
with open(embs_path, 'rb') as file:
    RNA_emb_dict = pickle.load(file)

# è¯»å–ä¿å­˜æ ‡ç­¾ tensor çš„å­—å…¸
labels_path = '/home/meixy23/TVAE/Rf1_RNA_pair_labels_dict.pkl'
with open(labels_path, 'rb') as file:
    RNA_pair_labels_dict = pickle.load(file)

#################################################################################
## å®šä¹‰å‡½æ•°ï¼šè®¡ç®—è¯„ä»·æŒ‡æ ‡
def Cal_eval_score(model, dataset, Name):
    # è¯„ä¼°æ¨¡å‹
    model.eval()

    # åˆå§‹åŒ– TPã€FPã€FN
    TP, FP, FN = 0, 0, 0

    for idx, (RNA_emb, label) in enumerate(dataset):
        # æŠŠ RNA_emb å’Œ label ç§»åŠ¨åˆ°è®¾å¤‡ä¸Š
        # RNA_emb = torch.from_numpy(RNA_emb).to(device)
        # label = torch.from_numpy(label).to(device) if isinstance(label, np.ndarray) else label  # ç¡®ä¿ label æ˜¯ tensor
        RNA_emb = RNA_emb.to(device)

        # å¾—åˆ°é…å¯¹çŸ©é˜µ
        with torch.no_grad():
            out, _, _ = model(RNA_emb.unsqueeze(0))

        # å¾—åˆ°æ ‡ç­¾å’Œé…å¯¹çŸ©é˜µçš„ numpy å½¢å¼
        n_data = (torch.softmax(out[0, :, :], dim=-1)[:, :, 1] > 0.9).to(torch.int16).detach().cpu().numpy()
        pair_mat = label.detach().cpu().numpy()  # ç¡®ä¿ label æ˜¯ tensor

        if idx < 5:
            plt.imshow(n_data)
            plt.colorbar()
            plt.savefig(f'./Fig4/{str(idx).zfill(2)}{Name}_é¢„æµ‹.png')
            plt.close()
            plt.imshow(pair_mat)
            plt.colorbar()
            plt.savefig(f'./Fig4/{str(idx).zfill(2)}{Name}_çœŸå®.png')
            plt.close()

        # è®¡ç®—TP, FP, FN
        TP += np.sum((n_data == 1) & (pair_mat == 1))
        FP += np.sum((n_data == 1) & (pair_mat == 0))
        FN += np.sum((n_data == 0) & (pair_mat == 1))

    # è®¡ç®— Precision å’Œ Recall
    precision = TP / (TP + FP) if (TP + FP) > 0 else 0
    recall = TP / (TP + FN) if (TP + FN) > 0 else 0

    # è®¡ç®— F1 Score
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    print("å‡†ç¡®ç‡:", precision)
    print("å¬å›ç‡:", recall)
    print("F1 åˆ†æ•°:", f1_score)

    return f1_score



#################################################################################
## è‡ªå®šä¹‰ RNA æ•°æ®é›†ç±»
class RNADataset(Dataset):
    def __init__(self, data_list):
        """
        data_list æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å« (input_tensor, label_tensor) å…ƒç»„ã€‚
        """
        self.data_list = data_list

    def __len__(self):
        return len(self.data_list)

    def __getitem__(self, idx):
        return self.data_list[idx]


# åˆ›å»º data_ls
data_ls = []
sample_count = 0  # æ§åˆ¶æ‰“å°æ•°é‡
error_count = 0
error_keys = []

for key in RNA_pair_labels_dict.keys():
    key_upper = key.upper()

    if key_upper not in RNA_emb_dict:
        print(f"âŒ æ‰¾ä¸åˆ°åµŒå…¥ï¼š{key_upper}")
        continue

    # åˆ¤æ–­å®¶æ—ï¼Œæ˜¯å¦ä¸ºè®­ç»ƒé›†ä¸­åº”è¯¥å­˜åœ¨çš„å®¶æ—
    # Rfam = RNA_pair_labels_dict[key]['rfam_id']
    Rfam = RNA_pair_labels_dict[key][0]
    if Rfam + 1 == 5:
        continue

    # è·å–åµŒå…¥ã€å®¶æ—ã€é…å¯¹æ ‡ç­¾
    Emb = RNA_emb_dict[key_upper]
    # Pair_label = RNA_pair_labels_dict[key]['pair_matrix']
    Pair_label = RNA_pair_labels_dict[key][1]

    if Emb.shape[0] != Pair_label.shape[0]:
        # print(f"âŒ é•¿åº¦ä¸ä¸€è‡´ï¼key={key[:30]}..., emb_len={Emb.shape[0]}, label_len={Pair_label.shape[0]}")
        error_count += 1
        error_keys.append(key)
        continue

    # âœ… æ‰“å°è°ƒè¯•ä¿¡æ¯ï¼ˆåªæ‰“å°å‰3ä¸ªï¼‰
    # if sample_count < 3:
    #     print(f"\nâœ… Sample {sample_count + 1}")
    #     print(f"Key (åŸå§‹): {key}")
    #     print(f"Key (å¤§å†™): {key_upper}")
    #     print(f"Rfam: {Rfam}")
    #     print(f"Embedding shape: {Emb.shape}")
    #     print(f"Pair_label shape: {Pair_label.shape}")
    #     print(f"Embedding type: {type(Emb)}")
    #     print(f"Pair_label type: {type(Pair_label)}")
    #     sample_count += 1

    # æ·»åŠ åˆ°æ•°æ®åˆ—è¡¨ä¸­
    temp = (Emb, Pair_label)
    data_ls.append(temp)
print(f"\nâš ï¸ ä¸€å…±å‘ç° {error_count} ä¸ªé•¿åº¦ä¸ä¸€è‡´çš„æ ·æœ¬")
# åˆ›å»º dataset
dataset = RNADataset(data_ls)


print(f'\nğŸ“¦ æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼Œæ€»æ ·æœ¬æ•°ï¼š{len(dataset)}')

# assert False

#################################################################################
## å®šä¹‰å‡½æ•°ï¼šäº§ç”Ÿæ–¹é˜µä¸­çš„æ­£è´Ÿæ ·æœ¬æ©ç ï¼ˆåœ¨ 01 æ–¹é˜µä¸­ï¼Œéšæœºç”Ÿæˆä¸ 1 æ•°é‡ç›¸ç­‰çš„æ©ç ï¼‰
def Get_label_mask(label_tensor):
    lt = copy.deepcopy(label_tensor)

    # 1. è®¡ç®—å¼ é‡ä¸­å€¼ä¸º 1 çš„æ•°é‡ï¼Œè¿™ä¸ªæ•°é‡ä¹Ÿæ˜¯æ–¹é˜µä¸­åº”è¯¥æ·»åŠ  2 çš„ä¸ªæ•°
    num_ones = (lt == 1).sum()
    num_twos = num_ones.item()

    # 2. æ‰¾åˆ°æ‰€æœ‰å€¼ä¸º 0 çš„ä½ç½®
    zero_indices = torch.nonzero(lt == 0, as_tuple=False)

    # 3. ä»å€¼ä¸º 0 çš„ä½ç½®ä¸­éšæœºé€‰æ‹©ä¸ 1 çš„æ•°é‡ç›¸åŒçš„ä½ç½®
    perm = torch.randperm(zero_indices.size(0))
    selected_indices = zero_indices[perm[:num_twos]]

    # 4. å°†é€‰å®šä½ç½®çš„å€¼ä» 0 æ”¹ä¸º 2
    for idx in selected_indices:
        lt[idx[0], idx[1]] = 2

    # è¾“å‡ºç»“æœ
    return lt != 0


#################################################################################
## å®šä¹‰å‡½æ•°ï¼šç”¨æ¥å¤„ç† batch ä¸­æ•°æ®å¤§å°ä¸ä¸€è‡´çš„é—®é¢˜
def collate_fn(batch):
    """
    batch æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å« (input_tensor, label_tensor) å…ƒç»„ã€‚
    """

    # å°† batch åˆ—è¡¨ä¸­ (input_tensor, label_tensor) å…ƒç»„ä¸­çš„æ‰€æœ‰ input_tensor åˆæˆä¸€ä¸ªå…ƒç»„
    # æ‰€æœ‰çš„ label_tensor åˆæˆå¦ä¸€ä¸ªå…ƒç»„
    inputs, labels = zip(*batch)
    inputs = [torch.from_numpy(inp) if isinstance(inp, np.ndarray) else inp for inp in inputs]

    # è·å–æ¯ä¸ªè¾“å…¥çš„åºåˆ—é•¿åº¦
    seq_lengths = [input_tensor.size(0) for input_tensor in inputs]

    # è®¡ç®—æœ€é•¿çš„é•¿åº¦
    max_seq_len = max(seq_lengths)

    # å¯¹è¾“å…¥è¿›è¡Œå¡«å……
    padded_inputs = []
    padding_masks = []
    for input_tensor in inputs:
        pad_size = max_seq_len - input_tensor.size(0)
        if pad_size > 0:
            # å‡è®¾ input_tensor çš„å½¢çŠ¶ä¸º [seq_len, feature_dim]
            padding = torch.zeros(pad_size, input_tensor.size(1))
            # å¾—åˆ°æ©ç 
            padding_mask = torch.cat([torch.ones(input_tensor.size(0)), torch.zeros(padding.size(0))], dim=0).to(bool)
            # å¾—åˆ° padding åçš„è¾“å…¥
            padded_input = torch.cat([input_tensor, padding], dim=0)
        else:
            # å¾—åˆ°æ©ç 
            padding_mask = torch.ones(input_tensor.size(0)).to(bool)
            # å¾—åˆ° padding åçš„è¾“å…¥
            padded_input = input_tensor
        # æ·»åŠ åˆ°åˆ—è¡¨
        padded_inputs.append(padded_input)
        padding_masks.append(~padding_mask)
    # padded_inputs, padding_masks è½¬åŒ–æˆ tensorï¼špi, pm
    pi = torch.stack(padded_inputs)
    pm = torch.stack(padding_masks)

    # å¯¹æ ‡ç­¾è¿›è¡Œå¡«å……
    padded_labels = []
    label_masks = []
    for label_tensor in labels:
        label_tensor = torch.from_numpy(label_tensor) if isinstance(label_tensor, np.ndarray) else label_tensor

        Len = label_tensor.size(0)
        pad_size = max_seq_len - Len
        # å¾—åˆ°æ­£è´Ÿæ ·æœ¬çš„æ©ç 
        label_m = Get_label_mask(label_tensor)
        if pad_size > 0:
            # å¡«å……è¡Œ
            padding_rows = -1 * torch.ones(pad_size, label_tensor.size(1))
            label_tensor = torch.cat([label_tensor, padding_rows], dim=0)
            # å¡«å……åˆ—
            padding_cols = -1 * torch.ones(max_seq_len, pad_size)
            label_tensor = torch.cat([label_tensor, padding_cols], dim=1)
        # å¾—åˆ° padding åçš„æ ‡ç­¾æ©ç 
        label_pm = (label_tensor != -1)
        label_pm[:Len, :Len] = label_m
        # æ·»åŠ åˆ°åˆ—è¡¨é‡Œ
        padded_labels.append(label_tensor)
        label_masks.append(label_pm)
    # padded_labels, label_masks è½¬åŒ–æˆ tensorï¼špl, lm
    pl = torch.stack(padded_labels)
    lm = torch.stack(label_masks)

    '''print(pl[0, :20, :20])

    plt.imshow(pl[0].to(torch.int16).numpy())
    plt.colorbar()
    plt.savefig('1.png')
    plt.close()
    plt.imshow(lm[0].numpy())
    plt.colorbar()
    plt.savefig('2.png')
    assert False

    print(pl[0][lm[0]].shape)
    print(pl[0][lm[0]][:, 0].sum())
    assert False'''

    # è¾“å‡º padding åçš„åµŒå…¥ã€åµŒå…¥ padding çš„ä½ç½®ã€padding çš„æ ‡ç­¾ã€æ ‡ç­¾ padding çš„ä½ç½®
    return pi, pm, pl, lm


#################################################################################
## éƒ¨ç½²æ¨¡å‹ï¼Œåˆ›å»º DataLoaderï¼Œå®šä¹‰ä¼˜åŒ–å™¨ï¼Œå®šä¹‰æŸå¤±å‡½æ•°

# å¯¹è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¿›è¡Œåˆ’åˆ†ï¼ˆæŒ‰ç…§è¶…å‚æ•°ä¸­çš„æ¯”ä¾‹ï¼‰
total_size = len(dataset)
train_size = int(Train_Rate * total_size)
test_size = total_size - train_size
# è¿›è¡Œåˆ’åˆ†
train_dataset, test_dataset = random_split(dataset, [train_size, test_size])

# print(train_dataset[0][1].shape)
# assert False

# åˆ›å»º DataLoaderï¼ˆèƒ½ä½¿ç”¨ GPU çš„æ—¶å€™ï¼Œè¡¨ç¤ºåœ¨ï¼‰
if torch.cuda.is_available():
    train_loader = DataLoader(train_dataset, batch_size=BS, collate_fn=collate_fn, shuffle=True, num_workers=32)
    test_loader = DataLoader(test_dataset, batch_size=BS, collate_fn=collate_fn, shuffle=False, num_workers=32)
else:
    train_loader = DataLoader(train_dataset, batch_size=BS, collate_fn=collate_fn, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=BS, collate_fn=collate_fn, shuffle=False)

# éƒ¨ç½² KnotFold_Model æ¨¡å‹
model = TransformerVAE(
    input_dim=640,
    hidden_dim=256,
    num_heads=8,
    num_layers=4,
    dropout=DR)
model.to(device)

# ä¼˜åŒ–å™¨
# optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)
optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01, betas=(0.9, 0.999))
# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)


# if Read_Weight == True:
#     print('å·²ç»è¯»å–æ¨¡å‹å‚æ•°')
#     # è¯»å–å·²ç»ä¿å­˜çš„å‚æ•°
#     model.load_state_dict(torch.load('./Weight/model_checkpoint200.pth', map_location=torch.device(device)))
#     # åŠ è½½ä¼˜åŒ–å™¨çš„çŠ¶æ€å­—å…¸
#     optimizer.load_state_dict(torch.load('optimizer_state.pth'))

# å®šä¹‰æŸå¤±å‡½æ•°
criterion = nn.CrossEntropyLoss()

#################################################################################
## è®­ç»ƒæ¨¡å‹

# åˆå§‹åŒ–æŸå¤±å’Œç²¾åº¦å†å²è®°å½•
train_f1_score_ls = []
test_f1_score_ls = []

# ä¿å­˜æœ€å¤§çš„æµ‹è¯•é›†ä¸Šçš„ f1 åˆ†æ•°
max_test_f1_score = 0
max_test_f1_score_ls = []
import os  # åŠ åœ¨å¼€å¤´

# =================== åœ¨è®­ç»ƒå‰ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨ ====================
fig_dir = './Fig4'  # å®šä¹‰å›¾åƒä¿å­˜ç›®å½•
os.makedirs(fig_dir, exist_ok=True)
kl_max_weight = 0.1
kl_anneal_epochs = 100

epoch = 0
while True:
    epoch += 1

    # åˆ¤æ–­æ˜¯å¦æ»¡è¶³åœæ­¢æ¡ä»¶
    if num_epochs is not None:
        if epoch > num_epochs:
            break

    # è®¡ç®— KL åŠ¨æ€æƒé‡
    kl_weight = min(kl_max_weight, epoch / kl_anneal_epochs * kl_max_weight)
    # print(kl_weight)

    model.train()
    train_loss = 0.0
    count = 0

    for pi, pm, pl, lm in train_loader:
        # å°†æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡ä¸Š
        pi = pi.to(device)
        pm = pm.to(device)
        pl = pl.to(device).long()
        lm = lm.to(device)
        attention_mask = pm

        optimizer.zero_grad()
        px, mu, logvar = model(pi, attention_mask)

        ce_loss = criterion(px[lm], pl[lm])
        kl = model.kl_loss(mu, logvar, attention_mask)

        loss = (1 - kl_weight) * ce_loss + kl_weight * kl

        loss.backward()
        optimizer.step()


# å¼€å§‹è®­ç»ƒ
# epoch = 0
# while True:
#     epoch += 1
#
#     # åˆ¤æ–­æ˜¯å¦æ»¡è¶³åœæ­¢æ¡ä»¶
#     if num_epochs != None:
#         if epoch > num_epochs:
#             break
#
#     model.train()
#     train_loss = 0.0
#     count = 0
#     # ä½¿ç”¨ data_loader ä¸­çš„æ•°æ®è¿›è¡Œè®­ç»ƒ
#     for pi, pm, pl, lm in train_loader:
#         # å°†æ•°æ®ç§»åŠ¨åˆ° GPU æˆ– CPU ä¸Š
#         pi = pi.to(device)
#         pm = pm.to(device)
#         pl = pl.to(device).long()
#         lm = lm.to(device)
#         attention_mask = pm
#         # æ¢¯åº¦æ¸…é›¶
#         optimizer.zero_grad()
#         px, mu, logvar = model(pi, attention_mask)
#
#         ce_loss = criterion(px[lm], pl[lm])
#         kl = model.kl_loss(mu, logvar, attention_mask)
#         # if torch.isnan(kl):
#         #     print("KLä¸ºNAN")
#         # if torch.isnan(ce_loss):
#         #     raise ValueError("ce_loss è®¡ç®—åä¸ºnan")
#             # print(ce_loss)
#             # print(kl)
#         # assert False
#         loss = 0.8*ce_loss + 0.2*kl
#
#         loss.backward()
#         optimizer.step()

        # # è®¡ç®—è¾“å‡º
        # out = model(pi, pm)
        # outputs = out[lm]
        #
        # # è®¡ç®—æŸå¤±
        # loss = criterion(outputs, pl[lm])
        #
        # # å›ä¼ æŸå¤±
        # loss.backward()
        # optimizer.step()

        # ä¿å­˜è®­ç»ƒæŸå¤±
        train_loss += loss.item()

    # æ±‚è¿™ä¸ª epoch ä¸­çš„å¹³å‡æŸå¤±
    avg_train_loss = train_loss / len(train_loader)

    # è¯„ä¼°æµ‹è¯•é›†
    if epoch % 10 == 0:

        # æ‰“å°è¿›åº¦
        print(f'Epoch {epoch + 1}: Train Loss = {avg_train_loss}')

        # è®¡ç®—è¯„ä»·æŒ‡æ ‡
        print(f'è¯„ä»·è®­ç»ƒé›†ï¼ˆLenï¼š{len(train_dataset)}ï¼‰æ•ˆæœ')
        train_f1_score = Cal_eval_score(model, train_dataset, 'è®­ç»ƒ')
        print(f'è¯„ä»·æµ‹è¯•é›†ï¼ˆLenï¼š{len(test_dataset)}ï¼‰æ•ˆæœ')
        test_f1_score = Cal_eval_score(model, test_dataset, 'æµ‹è¯•')

        # æ·»åŠ åˆ°åˆ—è¡¨ä¸­
        train_f1_score_ls.append(train_f1_score)
        test_f1_score_ls.append(test_f1_score)

        # å¦‚æœå½“å‰çš„æµ‹è¯•é›†ä¸Šçš„ f1 åˆ†æ•°å¤§äºå†å²æœ€å¤§çš„ f1 åˆ†æ•°ï¼Œåˆ™ä¿å­˜æƒé‡
        if max_test_f1_score < test_f1_score:
            # æ›´æ–°æœ€å¤§çš„ f1 åˆ†æ•°
            max_test_f1_score = test_f1_score
            max_test_f1_score_ls.append(max_test_f1_score)
            # ä¿å­˜æ¨¡å‹å‚æ•°
            torch.save(model.state_dict(), f'./Weight4/0model_checkpoint.pth')
        else:
            max_test_f1_score_ls.append(max_test_f1_score)

        # å±•ç¤ºå½“å‰æœ€å¤§çš„æµ‹è¯•é›†ä¸Šçš„ f1 åˆ†æ•°
        print(f'å½“å‰æµ‹è¯•é›†æœ€å¤§çš„ f1 åˆ†æ•°æ˜¯ï¼š{max_test_f1_score}')
        print()

        # ç”»å›¾
        plt.plot(train_f1_score_ls)
        plt.plot(test_f1_score_ls)
        plt.plot(max_test_f1_score_ls)
        plt.title(f'max_test_f1_score: {max_test_f1_score}')
        plt.savefig(os.path.join(fig_dir, f'F1_score_epoch_{epoch}.png'))
        plt.close()

    # ä¿å­˜æ¨¡å‹å‚æ•°çš„ä¸­é—´è¿‡ç¨‹
    if epoch % 500 == 0 and epoch != 0:
        torch.save(model.state_dict(), f'./Weight4/model_checkpoint{epoch}.pth')

























