
# æŸ¥çœ‹PKLæ–‡ä»¶
# import pickle
#
# # æ›¿æ¢ä¸ºä½ å®é™…çš„æ–‡ä»¶è·¯å¾„
# file_path = '/home/meixy23/TVAE/Rf1_RNA_pair_labels_dict.pkl'
#
# with open(file_path, 'rb') as f:
#     data = pickle.load(f)
#
# # æ‰“å°ç±»å‹
# print("æ•°æ®ç±»å‹ï¼š", type(data))
#
# # å¦‚æœæ˜¯å­—å…¸ï¼Œæ‰“å°ä¸€ä¸ªé”®çš„å†…å®¹ï¼Œå¹¶ç»Ÿè®¡RNAåºåˆ—çš„æ€»æ•°
# if isinstance(data, dict):
#     total_sequences = len(data)  # è®¡ç®—å­—å…¸ä¸­é”®çš„æ•°é‡ï¼Œä¹Ÿå°±æ˜¯RNAåºåˆ—çš„æ€»æ•°
#     print(f"RNAåºåˆ—çš„æ€»æ•°ï¼š{total_sequences}")
#     first_key = next(iter(data))  # è·å–ç¬¬ä¸€ä¸ªé”®
#     print(f"é”®: {first_key}, å†…å®¹: {data[first_key]}")
# elif isinstance(data, list):
#     print(f"åˆ—è¡¨é•¿åº¦ï¼š{len(data)}, ç¬¬ä¸€ä¸ªå…ƒç´ å†…å®¹ï¼š{data[0]}")
# else:
#     print("å†…å®¹ï¼š", data[:1])


# æŸ¥çœ‹é…å¯¹çŸ©é˜µçš„å›¾åƒ

# import torch
# import matplotlib.pyplot as plt
# import os
# import pickle
#
#
# def load_pair_matrices_from_pkl(pkl_file):
#     """
#     ä»PKLæ–‡ä»¶åŠ è½½é…å¯¹çŸ©é˜µ
#     """
#     with open(pkl_file, 'rb') as f:
#         pair_dict = pickle.load(f)
#     return pair_dict
#
#
# def save_pair_matrices_as_images(pair_dict, output_dir):
#     """
#     å°†é…å¯¹çŸ©é˜µä¿å­˜ä¸ºå›¾åƒï¼Œå¹¶ä¿å­˜åˆ°æŒ‡å®šçš„ç›®å½•
#     """
#     if not os.path.exists(output_dir):
#         os.makedirs(output_dir)
#
#     for seq, (family, pair_matrix) in pair_dict.items():
#         # åˆ›å»ºå›¾åƒ
#         plt.figure(figsize=(8, 8))
#
#         # ç»˜åˆ¶çƒ­å›¾
#         plt.imshow(pair_matrix.numpy(), cmap='Blues', interpolation='nearest')
#
#         # è®¾ç½®æ ‡é¢˜
#         plt.title(f'Pair Matrix for {seq[:10]}...')  # ä»…æ˜¾ç¤ºåºåˆ—çš„å‰10ä¸ªå­—ç¬¦
#         plt.colorbar()
#
#         # ä¿å­˜å›¾åƒ
#         img_filename = f'{seq[:10]}_pair_matrix.png'  # æ–‡ä»¶åä½¿ç”¨åºåˆ—çš„å‰10ä¸ªå­—ç¬¦
#         img_path = os.path.join(output_dir, img_filename)
#         plt.savefig(img_path)
#         plt.close()  # å…³é—­å½“å‰å›¾åƒ
#
#     print(f"é…å¯¹çŸ©é˜µå›¾åƒå·²ä¿å­˜åˆ° {output_dir}")
#
#
# # ç¤ºä¾‹ç”¨æ³•
# pkl_file = '/home/meixy23/TVAE/NEW/output_pairs1.pkl'  # ä½ çš„PKLæ–‡ä»¶è·¯å¾„
# pair_dict = load_pair_matrices_from_pkl(pkl_file)
#
# output_dir = '/home/meixy23/TVAE/NEW/picture1'  # å›¾åƒä¿å­˜çš„æ–‡ä»¶å¤¹
# save_pair_matrices_as_images(pair_dict, output_dir)

# åˆæˆPKLæ–‡ä»¶ï¼ˆåµŒå…¥ï¼‰

# import os
# import numpy as np
# import torch
# from Bio import SeqIO
# import pickle
#
# # è·¯å¾„é…ç½®
# fasta_folder = '/home/meixy23/VAECNN-transformer/outFiles512quchong/train'
# embedding_folder = '/home/meixy23/VAECNN-transformer/qianru/train'
#
# # åˆå§‹åŒ–ç»“æœå­—å…¸
# RNA_emb_dict = {}
#
# # éå† fasta æ–‡ä»¶å¤¹
# for fasta_file in os.listdir(fasta_folder):
#     if not fasta_file.endswith(".fasta"):
#         continue
#
#     fasta_path = os.path.join(fasta_folder, fasta_file)
#     npy_path = os.path.join(embedding_folder, fasta_file + '.npy')  # ä¾‹å¦‚ seq_1.fasta.npy
#
#     if not os.path.exists(npy_path):
#         print(f"âŒ ç¼ºå¤±åµŒå…¥æ–‡ä»¶ï¼š{npy_path}ï¼Œè·³è¿‡")
#         continue
#
#     # è¯»å–åµŒå…¥
#     embedding = np.load(npy_path)  # shape: (L+2, 640)
#     # print(embedding.shape)
#     embedding = embedding.squeeze(0)         # å¦‚æœæ˜¯ (1, L+2, 640) -> (L+2, 640)
#     embedding = embedding[1:-1, :]           # å»æ‰é¦–å°¾ tokenï¼Œå¾—åˆ° LÃ—640
#     # print(embedding.shape)
#     # assert False
#     embedding_tensor = torch.tensor(embedding, dtype=torch.float32)
#
#     # è¯»å–åºåˆ—ï¼ˆç»Ÿä¸€è½¬å¤§å†™ï¼‰
#     records = list(SeqIO.parse(fasta_path, 'fasta'))
#     if len(records) != 1:
#         print(f"âš ï¸ æ–‡ä»¶ {fasta_file} ä¸­å­˜åœ¨å¤šæ¡åºåˆ—ï¼Œä»…å¤„ç†ç¬¬ä¸€æ¡")
#
#     seq = str(records[0].seq).upper()  # âœ… å¼ºåˆ¶è½¬å¤§å†™ï¼
#
#     if len(seq) != embedding_tensor.shape[0]:
#         print(f"âŒ åºåˆ—é•¿åº¦ä¸åµŒå…¥ä¸ä¸€è‡´ï¼š{fasta_file}ï¼Œè·³è¿‡")
#         continue
#
#     # âœ… ä½¿ç”¨å¤§å†™ RNA åºåˆ—ä½œä¸º key
#     RNA_emb_dict[seq] = embedding_tensor
#
# # ä¿å­˜ä¸º PKL æ–‡ä»¶
# with open('rna_dataset.pkl', 'wb') as f:
#     pickle.dump(RNA_emb_dict, f)
#
# print(f"âœ… RNA-FM åµŒå…¥å·²ä¿å­˜ï¼Œå…±è®¡ {len(RNA_emb_dict)} æ¡")



# åˆå¹¶PKLï¼ˆé…å¯¹çŸ©é˜µï¼‰
# import os
# import torch
# import pickle
# from Bio import SeqIO
#
# # åŠ è½½FASTAæ–‡ä»¶ï¼Œè¿”å› {åºåˆ—ID: åºåˆ—å­—ç¬¦ä¸²}
# def load_fasta_sequences(fasta_folder):
#     sequences = {}
#     for filename in sorted(os.listdir(fasta_folder)):
#         if filename.endswith(".fasta"):
#             file_path = os.path.join(fasta_folder, filename)
#             for record in SeqIO.parse(file_path, "fasta"):
#                 seq_str = str(record.seq)
#                 seq_id = os.path.splitext(filename)[0]  # æ–‡ä»¶åï¼ˆå»æ‰ .fastaï¼‰
#                 sequences[seq_id] = seq_str
#     return sequences
#
# # åŠ è½½ PT æ–‡ä»¶ï¼Œè¿”å› {åºåˆ—ID: é…å¯¹çŸ©é˜µ}
# def load_pairing_matrices(pt_folder):
#     matrices = {}
#     for filename in sorted(os.listdir(pt_folder)):
#         if filename.endswith(".pt"):
#             file_path = os.path.join(pt_folder, filename)
#             matrix = torch.load(file_path).float()
#             seq_id = os.path.splitext(filename)[0]  # æ–‡ä»¶åï¼ˆå»æ‰ .ptï¼‰
#             matrices[seq_id] = matrix
#     return matrices
#
# # è·¯å¾„é…ç½®
# fasta_folder = '/home/meixy23/VAECNN-transformer/outFiles512quchong/train'
# pt_folder = '/home/meixy23/KnotFold-master/contact/train'
#
# # åŠ è½½æ•°æ®
# sequences = load_fasta_sequences(fasta_folder)
# pairing_matrices = load_pairing_matrices(pt_folder)
#
# # æ„å»ºæœ€ç»ˆ dictï¼šä»¥ RNA åºåˆ—å­—ç¬¦ä¸²ä¸º keyï¼Œvalue = (0, é…å¯¹çŸ©é˜µ)
# RNA_pair_labels_dict = {}
# for key in pairing_matrices:
#     if key in sequences:
#         rna_seq = sequences[key]
#         matrix = pairing_matrices[key]
#         RNA_pair_labels_dict[rna_seq] = (0, matrix)  # å®¶æ—ç¼–å·è®¾ä¸º 0
#
# # ä¿å­˜ä¸º PKL æ–‡ä»¶
# pkl_filename = 'output_data.pkl'
# with open(pkl_filename, 'wb') as f:
#     pickle.dump(RNA_pair_labels_dict, f)
#
# print(f"âœ… å·²ä¿å­˜ä¸º dict æ ¼å¼ PKLï¼Œkey ä¸º RNA åºåˆ—å­—ç¬¦ä¸²ï¼Œå…±è®¡ {len(RNA_pair_labels_dict)} æ¡è®°å½•")

# æŸ¥çœ‹PKL
# import pickle
#
# # åŠ è½½åŸå§‹PKLæ–‡ä»¶
# with open('rna_dataset.pkl', 'rb') as f:
#     rna_dict = pickle.load(f)
#
# # åˆ›å»ºä¸€ä¸ªæ–°çš„å­—å…¸ï¼Œæ›´æ–°keyä¸ºå¤§å†™
# rna_dict_cleaned = {key.strip().upper(): value for key, value in rna_dict.items()}
#
# # ä¿å­˜ä¿®æ”¹åçš„å­—å…¸åˆ°æ–°çš„PKLæ–‡ä»¶
# with open('rna_dataset.pkl', 'wb') as f:
#     pickle.dump(rna_dict_cleaned, f)
#
# print("RNAåºåˆ—å·²è½¬åŒ–ä¸ºå¤§å†™å¹¶ä¿å­˜åˆ°æ–°çš„PKLæ–‡ä»¶ä¸­ï¼")

# ç”Ÿæˆé…å¯¹çŸ©é˜µ
#
# import os
# import pickle
# import numpy as np
#
# def read_fasta(fasta_path):
#     with open(fasta_path, 'r') as f:
#         lines = f.readlines()
#         seq = ''.join([line.strip() for line in lines if not line.startswith('>')])
#         return seq.upper()
#
# def read_ct(ct_path):
#     with open(ct_path, 'r') as f:
#         lines = f.readlines()
#
#     pairs = {}
#     seq = ''
#
#     for line in lines:
#         line = line.strip()
#         if line.startswith("#") or not line:
#             continue
#
#         parts = line.split()
#         if len(parts) < 6:
#             continue
#
#         try:
#             idx = int(parts[0])
#             base = parts[1]
#             pair_idx = int(parts[4])
#         except ValueError:
#             continue
#
#         seq += base
#         if pair_idx != 0:
#             i, j = min(idx, pair_idx) - 1, max(idx, pair_idx) - 1
#             pairs[(i, j)] = 1
#
#     return seq.upper(), pairs
#
# def generate_pair_matrix(length, pair_dict):
#     matrix = np.zeros((length, length), dtype=np.float32)
#     for (i, j) in pair_dict:
#         matrix[i, j] = 1.0
#         matrix[j, i] = 1.0
#     return matrix
#
# def build_pair_and_embedding_dict(fasta_dir, ct_dir, embedding_dir, contact_save_path, embedding_save_path):
#     pair_dict = {}
#     embedding_dict = {}
#     mismatch_count = 0
#     total_count = 0
#
#     for file in os.listdir(fasta_dir):
#         if not file.endswith('.fasta') and not file.endswith('.fa'):
#             continue
#
#         key = os.path.splitext(file)[0]
#         fasta_path = os.path.join(fasta_dir, file)
#         ct_path = os.path.join(ct_dir, key + '.ct')
#         embedding_path = os.path.join(embedding_dir, key + '.fasta.npy')
#
#         if not os.path.exists(ct_path):
#             print(f"âŒ ç¼ºå¤± CT æ–‡ä»¶: {key}.ct")
#             continue
#
#         if not os.path.exists(embedding_path):
#             print(f"âŒ ç¼ºå¤±åµŒå…¥æ–‡ä»¶: {key}.fasta.npy")
#             continue
#
#         seq_fasta = read_fasta(fasta_path)
#         seq_ct, pair_info = read_ct(ct_path)
#
#         if len(seq_fasta) != len(seq_ct) or seq_fasta != seq_ct:
#             print(f"âŒ åºåˆ—ä¸ä¸€è‡´ï¼{key} é•¿åº¦: fasta={len(seq_fasta)}, ct={len(seq_ct)}")
#             mismatch_count += 1
#             continue
#
#         embedding = np.load(embedding_path)
#         if embedding.ndim != 3 or embedding.shape[0] != 1 or embedding.shape[2] != 640:
#             print(f"âš ï¸ åµŒå…¥æ ¼å¼é”™è¯¯: {key}.fasta.npy, å½¢çŠ¶ä¸º {embedding.shape}")
#             mismatch_count += 1
#             continue
#
#         embedding = embedding[0, 1:-1, :]
#         if embedding.shape[0] != len(seq_fasta):
#             print(f"âŒ åµŒå…¥é•¿åº¦ä¸åºåˆ—ä¸ç¬¦: {key}, åµŒå…¥é•¿åº¦ {embedding.shape[0]}, åºåˆ—é•¿åº¦ {len(seq_fasta)}")
#             mismatch_count += 1
#             continue
#
#         pair_matrix = generate_pair_matrix(len(seq_fasta), pair_info)
#         pair_dict[str(seq_fasta)] = {
#             "rfam_id": 0,
#             "pair_matrix": pair_matrix
#         }
#         embedding_dict[str(seq_fasta)] = embedding
#         total_count += 1
#
#     print(f"\nâœ… ç”Ÿæˆå®Œæˆï¼šåŒ¹é…æˆåŠŸ {total_count} æ¡ï¼Œè·³è¿‡ {mismatch_count} æ¡ä¸ä¸€è‡´æ ·æœ¬ã€‚")
#
#     with open(contact_save_path, 'wb') as f:
#         pickle.dump(pair_dict, f)
#     print(f"ğŸ“¦ å·²ä¿å­˜é…å¯¹çŸ©é˜µè‡³ï¼š{contact_save_path}")
#
#     with open(embedding_save_path, 'wb') as f:
#         pickle.dump(embedding_dict, f)
#     print(f"ğŸ“¦ å·²ä¿å­˜åµŒå…¥æ–‡ä»¶è‡³ï¼š{embedding_save_path}")
#
# # ç¤ºä¾‹è°ƒç”¨ï¼ˆè·¯å¾„æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
# build_pair_and_embedding_dict(
#     fasta_dir='/home/meixy23/VAECNN-transformer/outFiles512quchong/train',
#     ct_dir='/home/meixy23/KnotFold-master/CTtrain',
#     embedding_dir='/home/meixy23/VAECNN-transformer/qianru/train',
#     contact_save_path='/home/meixy23/TVAE/contact/contact5.pkl',
#     embedding_save_path='/home/meixy23/TVAE/contact/embedding5.pkl'
# )

#  ç”ŸæˆåµŒå…¥æ–‡ä»¶
# import pickle
# import os
# import torch
#
#
# import torch
#
# def read_ct_file(ct_path, seq):
#     length = len(seq)
#     pair_matrix = torch.zeros((length, length))
#
#     with open(ct_path, 'r') as f:
#         lines = f.readlines()
#
#     for line in lines:
#         line = line.strip()
#         if not line:
#             continue
#         # è·³è¿‡æ³¨é‡Šè¡Œæˆ–åŒ…å«Energyçš„è¡Œ
#         if line.startswith('#') or 'Energy' in line or not line[0].isdigit():
#             continue
#         items = line.split()
#         if len(items) < 5:
#             continue
#         try:
#             idx = int(items[0]) - 1  # ä»0å¼€å§‹
#             paired_idx = int(items[4]) - 1  # ä¹Ÿæ˜¯ä»0å¼€å§‹
#             if 0 <= paired_idx < length:
#                 pair_matrix[idx, paired_idx] = 1
#                 pair_matrix[paired_idx, idx] = 1
#         except ValueError:
#             continue  # å¦‚æœæŸä¸€è¡Œæœ‰é—®é¢˜ï¼Œè·³è¿‡
#
#     return pair_matrix
#
#
#
# def process_data(input_pkl_path, ct_folder_path, output_feature_pkl_path, output_pair_pkl_path):
#     # åŠ è½½åŸå§‹è¾“å…¥æ•°æ®
#     with open(input_pkl_path, 'rb') as f:
#         data = pickle.load(f)
#
#     feature_dict = {}
#     pair_dict = {}
#
#     for seq, value in data.items():
#         # è§£ævalue
#         if isinstance(value, tuple) and len(value) == 3:
#             feature_tensor, family_id, seq_name = value
#         else:
#             raise ValueError(f"Unexpected value format for sequence {seq}")
#
#         # ä¿å­˜ç¬¬ä¸€ä¸ªpklï¼ˆåªä¿ç•™ç‰¹å¾ï¼‰
#         feature_dict[seq] = feature_tensor
#
#         # ç”ŸæˆCTæ–‡ä»¶è·¯å¾„ï¼Œå‡è®¾ctæ–‡ä»¶åæ˜¯seq_name+".ct"
#         ct_path = os.path.join(ct_folder_path, f"{seq_name}.ct")
#
#         if not os.path.exists(ct_path):
#             print(f"Warning: CT file not found for {seq_name}")
#             continue
#
#         pair_matrix = read_ct_file(ct_path, seq)
#         if pair_matrix is None:
#             print(f"Warning: CT file does not match sequence for {seq_name}")
#             continue
#
#         # ä¿å­˜ç¬¬äºŒä¸ªpklï¼ˆå®¶æ—IDå’Œé…å¯¹çŸ©é˜µï¼‰
#         pair_dict[seq] = (family_id, pair_matrix)
#
#     # ä¿å­˜ä¸¤ä¸ªpklæ–‡ä»¶
#     with open(output_feature_pkl_path, 'wb') as f:
#         pickle.dump(feature_dict, f)
#
#     with open(output_pair_pkl_path, 'wb') as f:
#         pickle.dump(pair_dict, f)
#
#     print(f"Saved feature pkl to {output_feature_pkl_path}")
#     print(f"Saved pair pkl to {output_pair_pkl_path}")
#
#
# # ä½¿ç”¨ç¤ºä¾‹
# input_pkl = '/home/meixy23/TVAE/NEW/Bases_emb_dict2.pkl'  # ä½ çš„ç¬¬ä¸€ç§æ ¼å¼çš„è¾“å…¥pkl
# ct_folder = '/home/meixy23/KnotFold-master/CTtrain'  # å­˜æ”¾ctæ–‡ä»¶çš„æ–‡ä»¶å¤¹
# output_feature_pkl = '/home/meixy23/TVAE/NEW/output_emb2.pkl'  # åªåŒ…å«åµŒå…¥ç‰¹å¾
# output_pair_pkl = '/home/meixy23/TVAE/NEW/output_pairs2.pkl'  # åŒ…å«å®¶æ—IDå’Œé…å¯¹çŸ©é˜µ
#
# process_data(input_pkl, ct_folder, output_feature_pkl, output_pair_pkl)


# æŸ¥çœ‹cpickleæ–‡ä»¶

# import pickle
# import numpy as np
# import torch
# from collections import namedtuple
#
# # å®šä¹‰ UFold ä½¿ç”¨çš„æ•°æ®ç»“æ„
# RNA_SS_data = namedtuple('RNA_SS_data', 'seq ss_label length name pairs')
#
# # One-hot æ˜ å°„å­—å…¸
# base_dict = {'A': 0, 'U': 1, 'C': 2, 'G': 3}
#
# def seq_to_onehot(seq):
#     onehot = np.zeros((len(seq), 4), dtype=np.float32)
#     for i, base in enumerate(seq):
#         if base in base_dict:
#             onehot[i, base_dict[base]] = 1.0
#     return onehot
#
# def contact_to_pairs(matrix, length):
#     """ä»çŸ©é˜µæå– base pairï¼Œå¹¶å¼ºåˆ¶è¿‡æ»¤æ‰éæ³•ç´¢å¼•"""
#     matrix = matrix.numpy() if isinstance(matrix, torch.Tensor) else matrix
#     pairs = []
#     for i in range(matrix.shape[0]):
#         for j in range(i + 1, matrix.shape[1]):
#             if matrix[i][j] > 0.5:
#                 if i < length and j < length:
#                     pairs.append([i, j])
#                     pairs.append([j, i])
#     return pairs
#
# def contact_to_label(matrix, length):
#     labels = np.zeros((length, 3), dtype=np.int64)
#     for i in range(length):
#         pair_found = False
#         for j in range(length):
#             if matrix[i][j] > 0.5:
#                 pair_found = True
#                 if i < j:
#                     labels[i][0] = 1  # å·¦é…å¯¹
#                     labels[j][2] = 1  # å³é…å¯¹
#                 break
#         if not pair_found:
#             labels[i][1] = 1  # æœªé…å¯¹
#     return labels
#
# def convert_dict_to_rnassdata(input_path, output_path):
#     with open(input_path, 'rb') as f:
#         data_dict = pickle.load(f)
#
#     dataset = []
#     skipped = 0
#     for idx, (seq_str, (family_id, matrix)) in enumerate(data_dict.items()):
#         length = len(seq_str)
#         name = f"RNA_{idx}"
#
#         try:
#             matrix = matrix.numpy() if isinstance(matrix, torch.Tensor) else matrix
#             matrix = matrix[:length, :length]  # è£å‰ªé˜²æ­¢è¶Šç•Œ
#
#             seq = seq_to_onehot(seq_str)
#             ss_label = contact_to_label(matrix, length)
#             pairs = contact_to_pairs(matrix, length)
#
#             # å†æ¬¡è¿‡æ»¤ï¼ˆé˜²æ­¢æ•°æ®æ±¡æŸ“ï¼‰
#             for i, j in pairs:
#                 if i >= length or j >= length:
#                     raise ValueError(f"Pair ({i},{j}) out of bounds for length {length}")
#
#             dataset.append(RNA_SS_data(seq=seq, ss_label=ss_label, length=length, name=name, pairs=pairs))
#
#         except Exception as e:
#             print(f"â­ï¸ Skipping {name}: {e}")
#             skipped += 1
#             continue
#
#     with open(output_path, 'wb') as f:
#         pickle.dump(dataset, f, protocol=pickle.HIGHEST_PROTOCOL)
#
#     print(f"\nâœ… Conversion complete. Saved to: {output_path}")
#     print(f"âœ… Total kept: {len(dataset)} | â­ï¸ Total skipped: {skipped}")
#
#
# # ====================
# # âœ… ä½¿ç”¨æ–¹æ³•ï¼šæ”¹è·¯å¾„
# # ====================
# # è¾“å…¥ä½ çš„ .pkl è·¯å¾„ å’Œ è¾“å‡ºçš„ .cPickle æ–‡ä»¶è·¯å¾„
# input_path = '/home/meixy23/TVAE/Rf1_RNA_pair_labels_dict.pkl'
# output_path = '/home/meixy23/UFold/data/TS2.cPickle'
#
# # æ‰§è¡Œè½¬æ¢
# convert_dict_to_rnassdata(input_path, output_path)



# #
# # ç”¨æ³•ç¤ºä¾‹
# convert_dict_to_rnassdata('/home/meixy23/TVAE/Rf1_RNA_pair_labels_dict.pkl', '/home/meixy23/UFold/data/TS2.cPickle')

# è½¬åŒ–ä¸ºbpseq

# import pickle
# import os
# import torch
#
# def convert_pair_matrix_to_bpseq(seq, pair_matrix):
#     """ä»é…å¯¹çŸ©é˜µä¸­æå–bpseqæ ¼å¼"""
#     L = len(seq)
#     pairings = [0] * L  # åˆå§‹åŒ–é…å¯¹ä½ç½®
#
#     # é¿å…é‡å¤è®°å½•ï¼Œåªå–ä¸Šä¸‰è§’
#     for i in range(L):
#         for j in range(i+1, L):
#             if pair_matrix[i, j] == 1:
#                 pairings[i] = j + 1  # bpseqæ˜¯1-based
#                 pairings[j] = i + 1
#
#     bpseq_lines = []
#     for i in range(L):
#         bpseq_lines.append(f"{i+1} {seq[i]} {pairings[i]}")
#     return bpseq_lines
#
# def save_bpseq_file(bpseq_lines, output_path):
#     with open(output_path, 'w') as f:
#         for line in bpseq_lines:
#             f.write(line + '\n')
#
# def pkl_to_bpseq(pkl_path, output_dir):
#     os.makedirs(output_dir, exist_ok=True)
#     with open(pkl_path, 'rb') as f:
#         data = pickle.load(f)
#
#     for idx, (seq, (family_id, pair_matrix)) in enumerate(data.items()):
#         if isinstance(pair_matrix, torch.Tensor):
#             pair_matrix = pair_matrix.numpy()
#         bpseq_lines = convert_pair_matrix_to_bpseq(seq, pair_matrix)
#         # ä»¥åºå·å‘½åï¼Œæˆ–ä»¥åºåˆ—å‰10ä¸ªå­—ç¬¦å‘½åä¹Ÿå¯
#         filename = f"seq_{idx+1}.bpseq"
#         output_path = os.path.join(output_dir, filename)
#         save_bpseq_file(bpseq_lines, output_path)
#
#     print(f"è½¬æ¢å®Œæˆï¼Œç”Ÿæˆäº† {len(data)} ä¸ªbpseqæ–‡ä»¶ï¼Œä¿å­˜åœ¨ï¼š{output_dir}")
#
# # ç¤ºä¾‹ç”¨æ³•
# pkl_to_bpseq('/home/meixy23/TVAE/NEW/output_pairs1.pkl', '/home/meixy23/UFold/test1')


# æŸ¥çœ‹pickleæ–‡ä»¶
# import pickle
# import collections
# RNA_SS_data = collections.namedtuple('RNA_SS_data',
#     'seq ss_label length name pairs')
#
# file_path = '/home/meixy23/e2efold-master/data/rnastralign_all_600/rnastralign_all_600/test_no_redundant_600.pickle'  # æ›¿æ¢ä¸ºä½ çš„æ–‡ä»¶è·¯å¾„
#
# with open(file_path, 'rb') as f:
#     data = pickle.load(f)
#
# print("æ•°æ®ç±»å‹:", type(data))
#
# # å¦‚æœæ˜¯å­—å…¸ï¼Œåªæ‰“å°å‰3ä¸ªé”®å€¼å¯¹
# if isinstance(data, dict):
#     for i, (k, v) in enumerate(data.items()):
#         print(f"[{i}] Key: {k} -> Type: {type(v)}")
#         if i >= 2:
#             break
#
# # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œåªæ‰“å°å‰3ä¸ªå…ƒç´ 
# elif isinstance(data, list):
#     for i, item in enumerate(data[:3]):
#         print(f"[{i}] {item} (Type: {type(item)})")
#
# # å…¶ä»–ç±»å‹ï¼Œç›´æ¥æ‰“å°
# else:
#     print(data)


# BPSEQè½¬åŒ–ä¸ºCTæ–‡ä»¶
# def bpseq_to_ct(bpseq_path, ct_path):
#     """
#     å°† BPSEQ æ ¼å¼æ–‡ä»¶è½¬æ¢ä¸º CT æ ¼å¼æ–‡ä»¶ã€‚
#     """
#     bases = []
#     pairings = []
#
#     # è¯»å– bpseq æ–‡ä»¶
#     with open(bpseq_path, 'r') as f:
#         for line in f:
#             if line.startswith('#') or not line.strip():
#                 continue
#             parts = line.strip().split()
#             if len(parts) < 3:
#                 continue
#             idx, base, pair = int(parts[0]), parts[1], int(parts[2])
#             bases.append(base)
#             pairings.append(pair)
#
#     n = len(bases)
#
#     with open(ct_path, 'w') as f:
#         # å†™å…¥ header
#         f.write(f"{n}  ENERGY = 0\n")
#         for i in range(n):
#             index = i + 1
#             base = bases[i]
#             prev_idx = i if i > 0 else 0
#             next_idx = i + 2 if i < n - 1 else 0
#             pair = pairings[i]
#             f.write(f"{index} {base} {prev_idx} {next_idx} {pair} {index}\n")
#
#     print(f"å·²è½¬æ¢: {bpseq_path} â†’ {ct_path}")
#
#
# # âœ… ç¤ºä¾‹è°ƒç”¨ï¼š
# bpseq_file = "/home/meixy23/mxfold2-master/output_bpseq/RNA_sequence.bpseq"
# ct_file = "/home/meixy23/mxfold2-master/example2.ct"
# bpseq_to_ct(bpseq_file, ct_file)


# ä»CTä¸­æå–RNAåºåˆ—
#
# def extract_sequence_from_ct(ct_path):
#     """
#     ä» CT æ–‡ä»¶ä¸­æå– RNA åºåˆ—ã€‚
#     """
#     sequence = []
#     with open(ct_path, 'r') as f:
#         lines = f.readlines()[1:]  # è·³è¿‡ç¬¬ä¸€è¡Œæ ‡é¢˜
#         for line in lines:
#             parts = line.strip().split()
#             if len(parts) >= 2:
#                 sequence.append(parts[1].upper())
#     return ''.join(sequence)
#
# def save_sequence_to_fasta(sequence, fasta_path, header="RNA_sequence"):
#     """
#     å°† RNA åºåˆ—ä¿å­˜ä¸º FASTA æ–‡ä»¶æ ¼å¼ã€‚
#     """
#     with open(fasta_path, 'w') as f:
#         f.write(f">{header}\n")
#         # å¯é€‰ï¼šæ¯è¡Œé™åˆ¶ä¸º60å­—ç¬¦ï¼Œæ ‡å‡†FASTAé£æ ¼
#         for i in range(0, len(sequence), 60):
#             f.write(sequence[i:i+60] + "\n")
#
# # ç¤ºä¾‹è·¯å¾„
# ct_file = "/home/meixy23/mxfold2-master/sequence_18.ct"
# fasta_file = "/home/meixy23/mxfold2-master/output18.fasta"
#
# # æå–å¹¶ä¿å­˜
# rna_seq = extract_sequence_from_ct(ct_file)
# save_sequence_to_fasta(rna_seq, fasta_file)
#
# print(f"å·²å°† RNA åºåˆ—ä¿å­˜ä¸º {fasta_file}")

# æ•°æ®ç”Ÿæˆå®Œæ•´æµç¨‹
#
# import os
# import pickle
# import torch
# import fm
# from tqdm import tqdm
#
# # ------------------------------
# # é…ç½® GPU è®¾å¤‡ï¼šä½¿ç”¨ GPU 1ï¼ˆç¼–å·ä» 0 å¼€å§‹ï¼‰
# device = torch.device("cuda:1" if torch.cuda.is_available() else "cpu")
# print(f"Using device: {device}")
#
# # é…ç½® RNA-FM æ¨¡å‹
# class Config:
#     class MODEL:
#         BACKBONE_NAME = "rna-fm"
#         PAIRWISE_PREDICTOR_NAME = "none"
#         BACKBONE_FROZEN = 1
#         MODEL_LOCATION = "/home/meixy23/VAECNN-transformer/RNA-FM/RNA-FM_pretrained.pth"  # ä¿®æ”¹ä¸ºä½ çš„è·¯å¾„
#
# cfg = Config()
# model = fm.downstream.build_model(cfg).to(device)
# alphabet = model.backbone_alphabet
# model.eval()
# batch_converter = alphabet.get_batch_converter()
# # ------------------------------
#
# # å¤šä¸ª CT æ–‡ä»¶å¤¹è·¯å¾„
# ct_folders = [
#     '/home/meixy23/KnotFold-master/CTtrain',
#     '/home/meixy23/KnotFold-master/CTVAL',
#     '/home/meixy23/KnotFold-master/CTtest'
# ]
#
# # è¾“å‡ºæ–‡ä»¶è·¯å¾„
# output_feature_pkl = '/home/meixy23/TVAE/NEW/output_emb4.pkl'     # RNAåºåˆ— -> åµŒå…¥
# output_pair_pkl = '/home/meixy23/TVAE/NEW/output_pairs4.pkl'     # RNAåºåˆ— -> (family_id, pair_matrix)
#
# # ========================
# # è¾…åŠ©å‡½æ•°ï¼šè¯»å– CT æ–‡ä»¶ç”Ÿæˆé…å¯¹çŸ©é˜µ
# def read_ct_file(ct_path, seq):
#     length = len(seq)
#     pair_matrix = torch.zeros((length, length))
#
#     with open(ct_path, 'r') as f:
#         lines = f.readlines()
#
#     for line in lines:
#         line = line.strip()
#         if not line or line.startswith('#') or 'Energy' in line or not line[0].isdigit():
#             continue
#         items = line.split()
#         if len(items) < 5:
#             continue
#         try:
#             idx = int(items[0]) - 1
#             paired_idx = int(items[4]) - 1
#             if 0 <= idx < length and 0 <= paired_idx < length:
#                 pair_matrix[idx, paired_idx] = 1
#                 pair_matrix[paired_idx, idx] = 1
#         except ValueError:
#             continue
#     return pair_matrix
#
# # ========================
# # ä¸»æµç¨‹
# feature_dict = {}
# pair_dict = {}
# count = 0
#
# for ct_folder in ct_folders:
#     ct_files = [f for f in os.listdir(ct_folder) if f.endswith('.ct')]
#
#     for ct_file in tqdm(ct_files, desc=f"Processing folder: {ct_folder}"):
#         key = ct_file.replace('.ct', '')
#         ct_path = os.path.join(ct_folder, ct_file)
#
#         # è¯»å– RNA åºåˆ—
#         with open(ct_path, 'r') as f:
#             lines = f.readlines()
#         valid_lines = [line for line in lines if not line.startswith('#') and line.strip()]
#         if len(valid_lines) < 2:
#             continue
#         RNA_seq = ''.join([line.split()[1] for line in valid_lines[1:] if len(line.split()) >= 5])
#         if len(RNA_seq) == 0 or len(RNA_seq) >= 511:
#             continue
#
#         # 1. åµŒå…¥è®¡ç®—ï¼ˆGPUï¼‰
#         try:
#             data = [("RNA", RNA_seq)]
#             batch_labels, batch_strs, batch_tokens = batch_converter(data)
#             batch_tokens = batch_tokens.to(device)  # ç§»åŠ¨åˆ°GPU
#             input_data = {
#                 "description": batch_labels,
#                 "token": batch_tokens
#             }
#             with torch.no_grad():
#                 results = model(input_data)
#                 embedding = results['representations'][12][0, :, :][1:-1, :].cpu()  # ä»GPUè½¬å›CPUä¿å­˜
#         except Exception as e:
#             print(f"[Error] Embedding failed for {key}: {e}")
#             continue
#
#         # 2. é…å¯¹çŸ©é˜µ
#         try:
#             pair_matrix = read_ct_file(ct_path, RNA_seq)
#             if embedding.shape[0] != pair_matrix.shape[0]:
#                 print(f"[Warning] Length mismatch for {key}: emb={embedding.shape[0]}, pair={pair_matrix.shape[0]}")
#                 continue
#         except Exception as e:
#             print(f"[Error] Pair matrix failed for {key}: {e}")
#             continue
#
#         # 3. ä¿å­˜ï¼ˆç¡®ä¿ä¸€ä¸€å¯¹åº”ï¼‰
#         feature_dict[RNA_seq] = embedding
#         pair_dict[RNA_seq] = (0, pair_matrix)  # family_id è®¾ä¸º0ï¼Œå¦‚æœ‰éœ€è¦å¯æ›¿æ¢
#
#         count += 1
#         if count >= 40000:
#             break
#     if count >= 40000:
#         break
#
# # ========================
# # ä¿å­˜ pkl æ–‡ä»¶
# with open(output_feature_pkl, 'wb') as f:
#     pickle.dump(feature_dict, f)
# with open(output_pair_pkl, 'wb') as f:
#     pickle.dump(pair_dict, f)
#
# print(f"\nâœ… Finished! Saved {count} RNAs.")
# print(f" - Feature PKL: {output_feature_pkl}")
# print(f" - Pair PKL: {output_pair_pkl}")


# ç”Ÿæˆå°æç´å›¾


# import pandas as pd
# import seaborn as sns
# import matplotlib.pyplot as plt
# import os
#
# # è®¾ç½®è¾“å‡ºç›®å½•
# output_dir = "/home/meixy23/TVAE/MXfold2"
# os.makedirs(output_dir, exist_ok=True)
#
# # æ­£ç¡®è¯»å–æ•°æ®ï¼ˆæ”¯æŒç©ºæ ¼æˆ–tabç­‰åˆ†éš”ç¬¦ï¼‰
# df_raw = pd.read_csv("/home/meixy23/TVAE/MXfold2/result1.csv", sep=r"\s+", header=None, engine='python')
#
# # å–å‡º 'Name', 'Precision', 'Recall', 'F1'
# df_metrics = df_raw[[0, 8, 9, 10]]
# df_metrics.columns = ['Name', 'Precision', 'Recall', 'F1']
#
# # è½¬æ¢ä¸ºé•¿è¡¨ï¼ˆä¾¿äºç”»å›¾ï¼‰
# df_melted = pd.melt(df_metrics, id_vars='Name',
#                     value_vars=['Precision', 'Recall', 'F1'],
#                     var_name='Metric', value_name='Score')
#
# # è®¾ç½® Seaborn é£æ ¼
# sns.set(style="whitegrid")
#
# # åˆ›å»ºæ¨ªå‘å°æç´å›¾
# plt.figure(figsize=(8, 4))  # ç˜¦é•¿å›¾
# sns.violinplot(
#     data=df_melted,
#     x='Score',
#     y='Metric',  # æ¨ªç€çš„å…³é”®åœ¨è¿™é‡Œ
#     palette='Set2',
#     cut=0,
#     inner='box',
#     linewidth=1.2,
#     width=0.6
# )
#
# plt.xlim(0, 1)
# plt.xlabel("Score")
# plt.ylabel("Metric")
# plt.title("Distribution of Precision / Recall / F1")
#
# # ä¿å­˜å›¾åƒ
# save_path = os.path.join(output_dir, "horizontal_violin.svg")
# plt.tight_layout()
# plt.savefig(save_path, format='svg')
# plt.close()
#
# print(f"âœ… æ¨ªå‘å°æç´å›¾å·²ä¿å­˜è‡³: {save_path}")




# ç”Ÿæˆè¡¨æ ¼

# ç¯å¢ƒé‡ç½®åé‡æ–°æ‰§è¡Œç»˜åˆ¶è¡¨æ ¼å›¾åƒçš„ä»£ç 
# import matplotlib
# matplotlib.use('Agg')  # âœ… é€‚ç”¨äºæ— GUIæœåŠ¡å™¨ç¯å¢ƒ
# import matplotlib.pyplot as plt
# import pandas as pd
# import numpy as np
# import os
#
# # å®šä¹‰æ¨¡å‹åŠå¯¹åº”æŒ‡æ ‡
# models = [
#     "TVAE", "UFold", "SPOT-RNA", "RNAstructure", "RNAFold",
#     "MXFold", "MXFold2", "KnotFold", "E2EFold"
# ]
# precision = [0.8280, 0.5681, 0.5417, 0.6380, 0.5324, 0.5829, 0.6101, 0.7164, 0.2697]
# recall    = [0.8928, 0.6687, 0.5987, 0.7487, 0.6487, 0.6434, 0.7096, 0.8327, 0.2574]
# f1_score  = [0.8592, 0.5953, 0.5778, 0.6723, 0.5683, 0.6125, 0.6433, 0.7677, 0.2531]
#
# # åˆ›å»º DataFrame
# df = pd.DataFrame({
#     'Model': models,
#     'Precision': precision,
#     'Recall': recall,
#     'F1 Score': f1_score
# })
#
# # è®¾ç½®å›¾åƒè¾“å‡ºç›®å½•
# output_dir = "./violin_plots"
# os.makedirs(output_dir, exist_ok=True)
# output_path = os.path.join(output_dir, "model_comparison_table.png")
#
# # ç»˜åˆ¶è¡¨æ ¼
# fig, ax = plt.subplots(figsize=(10, 3))
# ax.axis('off')
# table = ax.table(
#     cellText=df.round(4).values,
#     colLabels=df.columns,
#     cellLoc='center',
#     loc='center'
# )
# table.auto_set_font_size(False)
# table.set_fontsize(11)
# table.scale(1.2, 1.5)
#
# # ä¿å­˜ä¸ºPNG
# plt.savefig(output_path, dpi=300, bbox_inches='tight')
# plt.close()
#
# output_path


# æå–PKLæ•°æ®ï¼ˆå•ä¸ªï¼‰

# import pickle
#
# # === è®¾ç½®è·¯å¾„ ===
# input_path = '/home/meixy23/TVAE/Rf1_RNA_emb_dict.pkl'         # åŸå§‹PKLè·¯å¾„
# output_path = '/home/meixy23/TVAE/predict/sample_index_5.pkl'  # è¾“å‡ºæ–‡ä»¶è·¯å¾„
# target_index = 5  # æƒ³å–ç¬¬å‡ ä¸ªï¼ˆä»0å¼€å§‹è®¡æ•°ï¼‰
#
# # === åŠ è½½åŸå§‹PKLæ–‡ä»¶ ===
# with open(input_path, 'rb') as f:
#     data_dict = pickle.load(f)
#
# # === æå–ç¬¬ N ä¸ªæ ·æœ¬ ===
# if isinstance(data_dict, dict):
#     keys = list(data_dict.keys())
#
#     if target_index < len(keys):
#         key = keys[target_index]
#         value = data_dict[key]
#         one_sample_dict = {key: value}
#
#         # === ä¿å­˜ä¸ºæ–°PKLæ–‡ä»¶ ===
#         with open(output_path, 'wb') as out_f:
#             pickle.dump(one_sample_dict, out_f)
#
#         print(f'âœ… å·²æˆåŠŸæå–ç¬¬ {target_index} ä¸ªæ ·æœ¬å¹¶ä¿å­˜è‡³: {output_path}')
#         print(f'åºåˆ— key: {key}')
#     else:
#         print(f'âŒ è¾“å…¥ç´¢å¼• {target_index} è¶…å‡ºæ•°æ®èŒƒå›´ï¼ˆå…± {len(keys)} ä¸ªæ ·æœ¬ï¼‰')
# else:
#     print(f'âŒ åŠ è½½çš„å¯¹è±¡ä¸æ˜¯ dictï¼Œè€Œæ˜¯: {type(data_dict)}')


# æå–PKLæ•°æ®ï¼ˆå¤šä¸ªä¸ªï¼‰
# === æå–ç¬¬ start_idx åˆ° end_idx-1 çš„æ ·æœ¬ ===

import pickle

input_path = '/home/meixy23/TVAE/Rf1_RNA_emb_dict.pkl'
output_path = '/home/meixy23/TVAE/predict/sample.pkl'

start_idx = 10
end_idx = 30  # ä¸åŒ…å«

with open(input_path, 'rb') as f:
    data_dict = pickle.load(f)

if isinstance(data_dict, dict):
    keys = list(data_dict.keys())
    selected_keys = keys[start_idx:end_idx]
    extracted_dict = {k: data_dict[k] for k in selected_keys}

    with open(output_path, 'wb') as out_f:
        pickle.dump(extracted_dict, out_f)

    print(f'âœ… æˆåŠŸæå– {len(extracted_dict)} ä¸ªæ ·æœ¬: [{start_idx}, {end_idx})ï¼Œä¿å­˜è‡³: {output_path}')
    print(f'ç¤ºä¾‹ key åˆ—è¡¨: {[k[:20] for k in selected_keys]}')
else:
    print(f'âŒ åŠ è½½çš„å¯¹è±¡ä¸æ˜¯ dictï¼Œè€Œæ˜¯: {type(data_dict)}')


# æŸ¥çœ‹pklæ–‡ä»¶çš„æ•°é‡
# import pickle
#
# def count_rna_entries_in_file(pkl_file_path):
#     with open(pkl_file_path, 'rb') as f:
#         data = pickle.load(f)
#         if isinstance(data, dict):
#             entry_count = len(data)
#             print(f"æ–‡ä»¶ä¸­ RNA åºåˆ—çš„æ•°é‡ä¸º: {entry_count}")
#         else:
#             print("é”™è¯¯ï¼šè¯¥ pkl æ–‡ä»¶ä¸æ˜¯ä¸€ä¸ªå­—å…¸ç»“æ„ã€‚")
#
# # ç”¨æ³•ï¼šæ›¿æ¢ä¸ºä½ è‡ªå·±çš„æ–‡ä»¶è·¯å¾„
# pkl_file_path = '/home/meixy23/TVAE/NEW/output_emb4.pkl'
# count_rna_entries_in_file(pkl_file_path)

# åŒ¹é…CTæ–‡ä»¶

# import os
# import shutil
#
# def read_fasta_seq(fasta_path):
#     seq = []
#     with open(fasta_path, 'r') as f:
#         for line in f:
#             if line.startswith('>'):
#                 continue
#             seq.append(line.strip().upper())
#     return ''.join(seq)
#
#
# import numpy as np
#
#
# def parse_ct_file(filepath):
#     bases = []
#     pairs = []
#
#     with open(filepath, 'r') as f:
#         lines = f.readlines()
#
#     data_lines = [line.strip() for line in lines if line.strip() and not line.startswith('ENERGY')]
#
#     for line in data_lines[1:]:  # è·³è¿‡ç¬¬ä¸€è¡Œæ³¨é‡Š
#         parts = line.strip().split()
#         if len(parts) < 6:
#             continue
#         try:
#             idx = int(parts[0])
#             base = parts[1].upper()
#             pair = int(parts[4])
#
#             if base not in ['A', 'U', 'G', 'C', 'T', 'N']:  # æ”¯æŒ N å’Œ T
#                 # print(f"âš ï¸ è­¦å‘Š: CTæ–‡ä»¶ {filepath} è¡Œä¸­å‡ºç°éæ³•ç¢±åŸº '{base}'ï¼Œè·³è¿‡è¯¥è¡Œã€‚")
#                 continue
#
#             bases.append(base)
#             pairs.append(pair)
#         except ValueError:
#             # print(f"âš ï¸ è­¦å‘Š: éæ³•è¡Œï¼ˆéæ•´æ•°ç´¢å¼•ï¼‰â†’ {line}")
#             continue
#
#     L = len(bases)
#     ct_matrix = np.zeros((L, L), dtype=int)
#
#     for i, j in enumerate(pairs):
#         if j > 0 and j - 1 < L:
#             ct_matrix[i][j - 1] = 1
#             ct_matrix[j - 1][i] = 1
#
#     return ''.join(bases), ct_matrix
#
#
# def copy_matching_ct_files_by_seq(fasta_dir, ct_dir, output_dir):
#     os.makedirs(output_dir, exist_ok=True)
#
#     # è¯»å–FASTAåºåˆ—
#     fasta_seq_dict = {}
#     fasta_count = 0
#     for fasta_file in os.listdir(fasta_dir):
#         if fasta_file.endswith('.fasta') or fasta_file.endswith('.fa'):
#             fasta_path = os.path.join(fasta_dir, fasta_file)
#             seq = read_fasta_seq(fasta_path)
#             fasta_seq_dict[seq] = fasta_file
#             fasta_count += 1
#             # print(f"[FASTA] {fasta_file} â†’ é•¿åº¦: {len(seq)} å‰10ä¸ªç¢±åŸº: {seq[:10]}")
#
#     print(f"\nå…±è¯»å– {fasta_count} ä¸ªFASTAæ–‡ä»¶\n")
#
#     # è¯»å–å¹¶åŒ¹é…CTæ–‡ä»¶
#     ct_files = [f for f in os.listdir(ct_dir) if f.endswith('.ct')]
#     copied_count = 0
#     ct_count = 0
#
#     for ct_file in ct_files:
#         ct_path = os.path.join(ct_dir, ct_file)
#         seq_ct, _ = parse_ct_file(ct_path)
#         ct_count += 1
#         # print(f"[CT] {ct_file} â†’ é•¿åº¦: {len(seq_ct)} å‰10ä¸ªç¢±åŸº: {seq_ct[:10]}")
#
#         if seq_ct in fasta_seq_dict:
#             dst_path = os.path.join(output_dir, ct_file)
#             shutil.copy2(ct_path, dst_path)
#             copied_count += 1
#             # print(f"âœ… åŒ¹é…æˆåŠŸ: {ct_file} â†’ å¤åˆ¶")
#         # else:
#         #     print(f"âŒ æ— åŒ¹é…: {ct_file} â†’ ä¸åœ¨FASTAä¸­")
#
#     print(f"\nå…±å¤„ç† {ct_count} ä¸ªCTæ–‡ä»¶")
#     print(f"âœ… æ€»å…±å¤åˆ¶äº† {copied_count} ä¸ªåŒ¹é…çš„CTæ–‡ä»¶åˆ° {output_dir}")
#
# # ç¤ºä¾‹è°ƒç”¨ï¼Œæ›¿æ¢ä¸ºä½ çš„å®é™…è·¯å¾„
# copy_matching_ct_files_by_seq(
#     fasta_dir='/home/meixy23/VAECNN-transformer/outFiles512quchong/val',
#     ct_dir='/home/meixy23/KnotFold-master/ctFiles',
#     output_dir='/home/meixy23/KnotFold-master/CTVAL'
# )



# ç¤ºä¾‹è°ƒç”¨ï¼Œæ›¿æ¢ä¸ºä½ çš„å®é™…è·¯å¾„
# copy_matching_ct_files(
#     rna_seq_dir='/home/meixy23/VAECNN-transformer/outFiles512quchong/test',
#     ct_dir='/home/meixy23/KnotFold-master/ctFiles',
#     output_dir='/home/meixy23/KnotFold-master/CTtest'
# )


